{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dad7c1e0",
   "metadata": {},
   "source": [
    "decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a20e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load dataset\n",
    "categorical_df = pd.read_csv(\"categorical_dataset.csv\")\n",
    "np.random.seed(42)\n",
    "categorical_df[\"target\"] = np.random.choice([0, 1], size=len(categorical_df))\n",
    "X = categorical_df.drop(\"target\", axis=1)\n",
    "y = categorical_df[\"target\"]\n",
    "\n",
    "# preprocessing\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "preprocessor = ColumnTransformer([(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)])\n",
    "\n",
    "# pipeline\n",
    "dt = Pipeline([(\"pre\", preprocessor), (\"clf\", DecisionTreeClassifier(random_state=42))])\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Decision Tree Accuracy (Categorical):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c21ace",
   "metadata": {},
   "source": [
    "This program applies a Decision Tree Classifier to a dataset with categorical features. First, the dataset is loaded from categorical_dataset.csv. Since the dataset does not originally contain a target variable, a synthetic binary target (0 or 1) is generated randomly for demonstration purposes.\n",
    "\n",
    "The independent variables (X) are separated from the target (y). Because the dataset consists of categorical features, preprocessing is required. A ColumnTransformer is created using OneHotEncoder, which converts categorical variables into numerical values. This step is essential because decision trees in scikit-learn can only process numerical input.\n",
    "\n",
    "Next, a Pipeline is defined. The pipeline first applies preprocessing and then fits a DecisionTreeClassifier with a fixed random state for reproducibility. Pipelines make the process efficient and ensure that encoding and model training happen together without data leakage.\n",
    "\n",
    "The dataset is then split into training and testing subsets using an 80/20 split. The model is trained on the training set with .fit() and predictions are generated on the test set using .predict().\n",
    "\n",
    "Finally, the accuracy score is calculated using accuracy_score, which shows how well the decision tree performed on unseen data. This serves as a baseline model before exploring more advanced ensemble methods."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
