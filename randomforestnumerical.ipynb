{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3a7e7e",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load dataset\n",
    "numeric_df = pd.read_csv(\"numeric_dataset.csv\")\n",
    "np.random.seed(42)\n",
    "numeric_df[\"target\"] = np.random.choice([0, 1], size=len(numeric_df))\n",
    "X = numeric_df.drop(\"target\", axis=1)\n",
    "y = numeric_df[\"target\"]\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "print(\"Random Forest Accuracy (Numeric):\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93cced9",
   "metadata": {},
   "source": [
    "This Python script demonstrates building and evaluating a Random Forest classifier on a numeric dataset. The code begins by importing essential libraries: pandas and numpy for data handling, and scikit-learn modules for model training, splitting, and evaluation. The dataset is loaded from \"numeric_dataset.csv\" into a DataFrame named numeric_df. A synthetic binary target column \"target\" is generated using numpy.random.choice, with a fixed seed (np.random.seed(42)) to ensure reproducibility.\n",
    "\n",
    "Features (X) and target (y) are separated, and the data is split into training and testing sets in an 80:20 ratio using train_test_split. A RandomForestClassifier is instantiated with 100 trees (n_estimators=100) and a fixed random state. The model is trained on the training data with .fit(), and predictions are made on the test set using .predict(). The predictions are then evaluated against the actual labels using accuracy_score.\n",
    "\n",
    "Random Forest is an ensemble method based on bagging, where multiple decision trees are trained on random subsets of data and features. The final prediction is made via majority voting. This approach reduces overfitting, increases model stability, and typically outperforms a single decision tree. By aggregating multiple trees, Random Forest can capture complex relationships in numeric datasets while maintaining robustness to noise and variance, making it a widely used and reliable classifier for structured data."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
